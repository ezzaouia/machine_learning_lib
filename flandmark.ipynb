{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "#import dlib\n",
    "# import stasm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dlib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9039a0b0e92a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mPREDICTOR_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./shape_predictor_68_face_landmarks.dat\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frontal_face_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPREDICTOR_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dlib' is not defined"
     ]
    }
   ],
   "source": [
    "PREDICTOR_PATH = \"./shape_predictor_68_face_landmarks.dat\"\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(PREDICTOR_PATH)\n",
    "\n",
    "def get_landmarks(im):\n",
    "    rects = detector(im, 1)\n",
    "    \n",
    "    if len(rects) > 1:\n",
    "        raise TooManyFaces\n",
    "    if len(rects) == 0:\n",
    "        raise NoFaces\n",
    "\n",
    "    return np.array([[p.x, p.y] for p in predictor(im, rects[0]).parts()])\n",
    "\n",
    "def read_crop_image(image_path):\n",
    "    # image_pil = Image.open(image_path) #.convert('L')\n",
    "    image_pil = cv2.imread(image_path)\n",
    "    # Convert the image format into numpy array\n",
    "    # image = np.array(image_pil, 'uint8')\n",
    "\n",
    "    gray = cv2.cvtColor(image_pil, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        #cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "\n",
    "    image = np.array(roi_gray, 'uint8')\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 62, 131,  64, 148,  66, 164,  70, 180,  76, 195,  86, 208,  97,\n",
       "       220, 109, 228, 125, 230, 141, 229, 155, 221, 167, 210, 177, 198,\n",
       "       183, 183, 187, 167, 190, 150, 192, 132,  72, 119,  80, 110,  93,\n",
       "       107, 107, 109, 120, 114, 136, 113, 148, 108, 161, 106, 174, 109,\n",
       "       181, 119, 128, 128, 128, 141, 128, 153, 128, 166, 114, 172, 120,\n",
       "       174, 127, 177, 134, 175, 141, 173,  86, 129,  93, 126, 102, 126,\n",
       "       110, 131, 102, 132,  93, 132, 145, 130, 153, 125, 162, 125, 169,\n",
       "       129, 162, 132, 153, 132, 102, 191, 110, 187, 119, 186, 125, 188,\n",
       "       132, 187, 140, 190, 147, 196, 139, 202, 131, 205, 124, 204, 117,\n",
       "       203, 110, 198, 106, 191, 119, 191, 125, 192, 132, 192, 143, 195,\n",
       "       131, 196, 125, 196, 118, 194])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lanmark_pts = get_landmarks(img)\n",
    "lanmark_pts = lanmark_pts.flatten()\n",
    "lanmark_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "path = \"/Users/mohamed/Downloads/jaffe\"\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('./params/haarcascade_frontalface_default.xml')\n",
    "left_eye_cascade = cv2.CascadeClassifier('./params/haarcascade_lefteye_2splits.xml')\n",
    "right_eye_cascade = cv2.CascadeClassifier('./params/haarcascade_righteye_2splits.xml')\n",
    "sift = cv2.SIFT()\n",
    "\n",
    "# labels = {'Neutral': 0, 'Happy': 1, 'Sad': 2, 'Surprise': 3, 'Angry': 4, 'Disgust': 5, 'Fear': 6}\n",
    "labelsDic = {'NE': 0, 'HA': 1, 'SA': 2, 'SU': 3, 'AN': 4, 'DI': 5, 'FE': 6, 'CO': 7}\n",
    "\n",
    "\n",
    "# neutral image .. S506.NE.002.00000001.png\n",
    "neutral_image = read_crop_image(\"/Users/mohamed/Documents/999-images/01.HA.123.jpg\")\n",
    "\n",
    "# \"\"\"\"\"\"\n",
    "def load_jaffe_dataset(path):\n",
    "    images_paths = [os.path.join(path, f) for f in os.listdir(path) if  f.endswith('.png') or f.endswith('.tiffddd')]\n",
    "    scale_factor = 4\n",
    "    for image_path in images_paths:\n",
    "        \n",
    "        # image_pil = Image.open(image_path) #.convert('L')\n",
    "        image_pil = cv2.imread(image_path)\n",
    "        # Convert the image format into numpy array\n",
    "        # image = np.array(image_pil, 'uint8')\n",
    "\n",
    "        gray = cv2.cvtColor(image_pil, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        for (x,y,w,h) in faces:\n",
    "            #cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "\n",
    "        image = np.array(roi_gray, 'uint8')\n",
    "        \n",
    "        image_label_nbr = int(labelsDic.get(os.path.split(image_path)[1].split(\".\")[1][:2]))\n",
    "        landmark_vector = get_landmarks(image)\n",
    "        # add X-Y  diff of each image and neutreal image a feature too\n",
    "        landmark_vector_neutral = get_landmarks(neutral_image)\n",
    "        X = np.array([x[0] for x in landmark_vector])\n",
    "        Y = np.array([x[1] for x in landmark_vector])\n",
    "        \n",
    "        XNE = np.array([x[0] for x in landmark_vector_neutral])\n",
    "        YNE = np.array([x[1] for x in landmark_vector_neutral])\n",
    "        \n",
    "        XXNE = np.subtract(X,XNE)\n",
    "        YYNE = np.subtract(Y,YNE)\n",
    "        \n",
    "        XXNE = np.expand_dims(XXNE, axis=0)\n",
    "        YYNE = np.expand_dims(YYNE, axis=0)\n",
    "        \n",
    "        landmark_vector_augm = np.concatenate((landmark_vector, XXNE.T), axis=1)\n",
    "        landmark_vector_augm = np.concatenate((landmark_vector_augm, YYNE.T), axis=1)\n",
    "        images.append(landmark_vector.flatten())\n",
    "        labels.append(image_label_nbr)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "images, labels = load_jaffe_dataset(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328, 272)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = np.array(images, 'float64') #np.reshape(images, (images[]))\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(246, 272)\n",
      "(82, 272)\n",
      "246\n",
      "82\n",
      "done in 3.827s\n",
      "Best estimator found by grid search:\n",
      "SVC(C=4, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.0001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Baseline classifier using an SVM.\n",
      "55 of 82 values correct.\n",
      "accuracy is 67.073171 (%)\n"
     ]
    }
   ],
   "source": [
    "# Third-party libraries\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from time import time\n",
    "\n",
    "def svm_baseline():\n",
    "    # split into a training and testing set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "    images, labels, test_size=0.25, random_state=42)\n",
    "    print  X_train.shape\n",
    "    print  X_test.shape\n",
    "    print  len(y_train)\n",
    "    print  len(y_test)\n",
    "\n",
    "    # train\n",
    "    t0 = time()\n",
    "    param_grid = {'C': [1,4,8, 8.5, 1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "                  'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\n",
    "    clf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'), param_grid)\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print(\"Best estimator found by grid search:\")\n",
    "    print(clf.best_estimator_)\n",
    "\n",
    "    #clf = svm.SVC(C=8.5, gamma=0.0001)\n",
    "    #clf.fit(X_train, y_train)\n",
    "    # test\n",
    "    predictions = [int(a) for a in clf.predict(X_test)]\n",
    "    num_correct = sum(int(a == y) for a, y in zip(predictions, y_test))\n",
    "    print \"Baseline classifier using an SVM.\"\n",
    "    print \"%s of %s values correct.\" % (num_correct, len(y_test))\n",
    "    print \"accuracy is %f (%%)\" % (100 * num_correct * 1.0 / len(y_test))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    svm_baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(246, 272)\n",
      "(82, 272)\n",
      "246\n",
      "82\n",
      "done in 0.042s\n",
      "Baseline classifier using an SVM.\n",
      "55 of 82 values correct.\n",
      "accuracy is 67.073171 (%)\n"
     ]
    }
   ],
   "source": [
    "# Third-party libraries\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from time import time\n",
    "\n",
    "def svm_baseline():\n",
    "    # split into a training and testing set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "    images, labels, test_size=0.25, random_state=42)\n",
    "    print  X_train.shape\n",
    "    print  X_test.shape\n",
    "    print  len(y_train)\n",
    "    print  len(y_test)\n",
    "\n",
    "    # train\n",
    "    t0 = time()\n",
    "    clf = svm.SVC(C=80.5, gamma=0.0001)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    # test\n",
    "    predictions = [int(a) for a in clf.predict(X_test)]\n",
    "    num_correct = sum(int(a == y) for a, y in zip(predictions, y_test))\n",
    "    print \"Baseline classifier using an SVM.\"\n",
    "    print \"%s of %s values correct.\" % (num_correct, len(y_test))\n",
    "    print \"accuracy is %f (%%)\" % (100 * num_correct * 1.0 / len(y_test))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    svm_baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -4.03950617,  13.69382716,  -4.03950617, ...,  31.8       ,\n",
       "         36.43703704,   1.        ],\n",
       "       [ -8.03950617, -27.30617284,  -8.03950617, ..., -25.2       ,\n",
       "        -58.56296296,   1.        ],\n",
       "       [  2.96049383,   0.69382716,   2.96049383, ...,  20.8       ,\n",
       "         18.43703704,   1.        ],\n",
       "       ..., \n",
       "       [ 20.96049383,  15.69382716,  20.96049383, ...,  25.8       ,\n",
       "         72.43703704,   1.        ],\n",
       "       [ -6.03950617,  16.69382716,  -6.03950617, ...,  17.8       ,\n",
       "         46.43703704,   1.        ],\n",
       "       [-10.03950617, -36.30617284, -10.03950617, ..., -38.2       ,\n",
       "        -61.56296296,   1.        ]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    images, labels, test_size=0.25, random_state=42)\n",
    "mean_image = np.mean(X_train, axis=0)\n",
    "X_train -= mean_image\n",
    "X_test -= mean_image\n",
    "X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "\n",
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(405, 272)\n",
      "(136, 272)\n",
      "405\n",
      "136\n",
      "Baseline classifier using an SVM.\n",
      "83 of 136 values correct.\n",
      "accuracy is 61.029412 (%)\n"
     ]
    }
   ],
   "source": [
    "def svm_baseline2(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    print  X_train.shape\n",
    "    print  X_test.shape\n",
    "    print  len(y_train)\n",
    "    print  len(y_test)\n",
    "\n",
    "    # train\n",
    "    clf = svm.SVC(C=8.5, gamma=0.0001)\n",
    "    clf.fit(X_train, y_train)\n",
    "    # test\n",
    "    predictions = [int(a) for a in clf.predict(X_test)]\n",
    "    num_correct = sum(int(a == y) for a, y in zip(predictions, y_test))\n",
    "    for a, y in zip(predictions, y_test):\n",
    "        print \"prediction %d, lebel %d\" % (a, y)\n",
    "        \n",
    "    print \"Baseline classifier using an SVM.\"\n",
    "    print \"%s of %s values correct.\" % (num_correct, len(y_test))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    svm_baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "540"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "path = \"/Users/mohamed/Downloads/jaffe\"\n",
    "images_paths = [os.path.join(path, f) for f in os.listdir(path) if f.endswith('.tiff') or f.endswith('.png') ]\n",
    "len(images_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
